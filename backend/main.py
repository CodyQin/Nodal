import os
import json
import asyncio
from typing import List
from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv
from google import genai
from google.genai import types

load_dotenv()

app = FastAPI()

# å…è®¸è·¨åŸŸï¼Œæ–¹ä¾¿å‰ç«¯å¼€å‘
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))

# å®šä¹‰ System Promptï¼Œå¼ºè°ƒæ—¶é—´è½´å’Œå…³ç³»æŒ–æ˜
SYSTEM_PROMPT = """
You are an expert narrative analyst. Your job is to analyze the provided content (text or video) and construct a dynamic social network graph that evolves over time.

Output strict JSON format with the following structure:
{
  "timeline": [
    {
      "phase_name": "Phase 1: Introduction",
      "timestamp_start": "00:00", 
      "summary": "Brief summary of this phase",
      "nodes": [
        {"id": "char1", "label": "Name", "desc": "Role/Description", "centrality": 8}
      ],
      "edges": [
        {"source": "char1", "target": "char2", "relation": "Friend", "detail": "detail...", "sentiment": "positive", "weight": 5}
      ]
    },
    ... (more phases)
  ]
}

Rules:
1. Divide the story into 3-5 logical phases based on plot progression.
2. Sentiment must be 'positive', 'negative', or 'neutral'.
3. Centrality and Weight should be integers 1-10.
"""

@app.post("/api/analyze")
async def analyze_content(
    file: UploadFile = File(None),
    text_content: str = Form(None)
):
    try:
        if not file and not text_content:
            raise HTTPException(status_code=400, detail="No content provided")

        prompt_content = []
        
        # 1. å¦‚æœæ˜¯æ–‡ä»¶ (è§†é¢‘/PDF/æ–‡æœ¬æ–‡ä»¶)
        if file:
            print(f"Uploading file: {file.filename}...")
            # è¯»å–æ–‡ä»¶å­—èŠ‚æµ
            file_bytes = await file.read()
            
            # ä¸Šä¼ åˆ° Gemini File API (æ³¨æ„ï¼šè§†é¢‘æ–‡ä»¶å¯èƒ½è¾ƒå¤§ï¼Œå»ºè®®ç”¨ upload_file æ–¹æ³•)
            # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œç›´æ¥ä½œä¸º content å‘é€ (é€‚ç”¨äºå°æ–‡ä»¶/æ–‡æœ¬)
            # å¯¹äºå¤§è§†é¢‘ï¼Œæ­£å¼åšæ³•æ˜¯å…ˆ upload åˆ° Google File API æ‹¿åˆ° URI
            # ä¸‹é¢æ˜¯ç›´æ¥å°† Bytes ä¼ ç»™ Gemini (é€‚ç”¨äºæ–‡æœ¬æˆ–æçŸ­è§†é¢‘ç‰‡æ®µ)
            # å¦‚æœæ˜¯çº¯æ–‡æœ¬æ–‡ä»¶ï¼Œç›´æ¥decode
            if file.content_type.startswith("text/"):
                 prompt_content.append(file_bytes.decode("utf-8"))
            else:
                # å¯¹äºè§†é¢‘/å›¾åƒï¼Œéœ€è¦ä½¿ç”¨ upload_file é€»è¾‘ï¼Œè¿™é‡Œä¸ºäº† Hackathon æ¼”ç¤ºï¼Œ
                # å»ºè®®åœ¨ Demo ä¸­ä¸»è¦ä¸Šä¼ æ–‡æœ¬æˆ–PDFï¼Œè‹¥è¦ä¸Šä¼ è§†é¢‘ï¼Œéœ€ä½¿ç”¨ client.files.upload
                # ä¸‹é¢æ˜¯å¤„ç† Text input çš„é€»è¾‘ä¼˜å…ˆ
                pass 

        # 2. å¦‚æœæ˜¯çº¯æ–‡æœ¬è¾“å…¥
        if text_content:
            prompt_content.append(text_content)
        
        if not prompt_content:
             # ç®€å•çš„ Fallback: å‡è®¾ç”¨æˆ·ä¸Šä¼ äº†æ–‡æœ¬æ–‡ä»¶ä½†æ²¡è§£æå‡ºæ¥
             prompt_content.append("Analyze the implied story.")

        print("Sending request to Gemini 3...")
        
        # è°ƒç”¨ Gemini 3
        response = client.models.generate_content(
            model="gemini-3-flash-preview", # æš‚æ—¶ç”¨ 2.0 Flash Expï¼Œç­‰ 3 æ­£å¼å¯ç”¨æ—¶æ›¿æ¢ model name
            contents=[SYSTEM_PROMPT] + prompt_content,
            config=types.GenerateContentConfig(
                response_mime_type="application/json"
            )
        )

        print("\n" + "="*40)
        print("ğŸ¤– GEMINI 3:")
        print("="*40)
        print(response.text)  
        print("="*40 + "\n")

        return json.loads(response.text)

    except Exception as e:
        print(f"Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)