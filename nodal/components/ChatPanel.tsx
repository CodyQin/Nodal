import React, { useState, useRef, useEffect } from 'react';
import { Send, Bot, User, Loader2, Sparkles, MessageSquare } from 'lucide-react';
import { chatWithContextStream } from '../services/api';
import { AnalysisResult, ChatMessage } from '../types';

interface ChatPanelProps {
  analysisResult: AnalysisResult | null;
}

const PRESET_QUESTIONS = [
  "Who are the main characters?",
  "How do relationships change?",
  "What is the main conflict?",
  "Summarize the story timeline."
];

/**
 * A lightweight renderer for basic markdown generated by Gemini.
 * Handles bolding (**text**), bullet points (* item), and line breaks.
 */
const FormattedMessage: React.FC<{ text: string }> = ({ text }) => {
  const lines = text.split('\n');
  
  return (
    <div className="space-y-2 text-sm leading-relaxed">
      {lines.map((line, lineIdx) => {
        if (!line.trim()) return <div key={lineIdx} className="h-2" />;

        // Handle bullet points
        const isBullet = line.trim().startsWith('* ') || line.trim().startsWith('- ');
        const cleanLine = isBullet ? line.trim().substring(2) : line;

        // Process bold markers (**text**)
        const parts = cleanLine.split(/(\*\*.*?\*\*)/g);
        const content = parts.map((part, partIdx) => {
          if (part.startsWith('**') && part.endsWith('**')) {
            return <strong key={partIdx} className="font-bold text-white">{part.slice(2, -2)}</strong>;
          }
          return part;
        });

        if (isBullet) {
          return (
            <div key={lineIdx} className="flex gap-2 pl-1">
              <span className="text-blue-400 font-bold">â€¢</span>
              <span>{content}</span>
            </div>
          );
        }

        return <p key={lineIdx}>{content}</p>;
      })}
    </div>
  );
};

const ChatPanel: React.FC<ChatPanelProps> = ({ analysisResult }) => {
  const [messages, setMessages] = useState<ChatMessage[]>([
    { role: 'ai', content: 'Hi! I\'ve analyzed the story graph. Ask me anything about the characters, relationships, or how the plot develops across phases!' }
  ]);
  const [input, setInput] = useState('');
  const [isLoading, setIsLoading] = useState(false);
  const messagesEndRef = useRef<HTMLDivElement>(null);

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  };

  useEffect(() => {
    scrollToBottom();
  }, [messages, isLoading]);

  // Reset chat when a new analysis is loaded
  useEffect(() => {
    if (analysisResult) {
       setMessages([{ role: 'ai', content: 'Hi! I\'ve analyzed the story graph. Ask me anything about the characters, relationships, or how the plot develops across phases!' }]);
    }
  }, [analysisResult]);

  const handleSend = async (textOverride?: string | React.SyntheticEvent) => {
    // Determine the text to send: explicit string argument or current input state
    const userMsg = typeof textOverride === 'string' ? textOverride : input.trim();
    
    if (!userMsg || isLoading || !analysisResult) return;

    // Only clear input if we sent from the input field
    if (typeof textOverride !== 'string') {
      setInput('');
    }
    
    // Add user message AND placeholder AI message immediately
    setMessages(prev => [
      ...prev, 
      { role: 'user', content: userMsg },
      { role: 'ai', content: '' }
    ]);
    setIsLoading(true);

    // Helper to sanitize a single graph's nodes/edges to save tokens/noise
    const sanitizeGraphData = (nodes: any[], edges: any[]) => ({
      nodes: nodes.map(n => ({
        id: n.id,
        label_original: n.label_original,
        label_en: n.label_en,
        description: n.description_en || n.description_original || n.description,
      })),
      edges: edges.map(e => ({
        source: typeof e.source === 'object' ? (e.source as any).id : e.source,
        target: typeof e.target === 'object' ? (e.target as any).id : e.target,
        relation: {
          type: e.relation.type_en || e.relation.type_original,
          label: e.relation.label_en || e.relation.label_original,
        }
      }))
    });

    const prepareContext = (data: AnalysisResult): any => {
      // 1. Timeline Mode (Rich Context)
      if (data.timeline && data.timeline.length > 0) {
        return {
          type: "timeline_graph",
          timeline: data.timeline.map(phase => ({
            phase_id: phase.phase_id,
            phase_name_original: phase.phase_name_original,
            phase_name_en: phase.phase_name_en,
            summary_original: phase.summary_original,
            summary_en: phase.summary_en,
            graph: sanitizeGraphData(phase.graph.nodes, phase.graph.edges)
          }))
        };
      } 
      
      // 2. Single Graph Mode (Legacy/Fallback)
      if (data.nodes) {
        return {
          type: "single_graph",
          ...sanitizeGraphData(data.nodes, data.edges || [])
        };
      }

      return {};
    };

    const history = messages.map(m => ({ role: m.role, content: m.content }));
    const cleanContext = prepareContext(analysisResult);

    try {
      await chatWithContextStream(userMsg, cleanContext, history, (chunk) => {
        setMessages(prev => {
          const newMessages = [...prev];
          const lastMsg = newMessages[newMessages.length - 1];
          // Ensure we are updating the last AI message
          if (lastMsg && lastMsg.role === 'ai') {
            newMessages[newMessages.length - 1] = {
              ...lastMsg,
              content: lastMsg.content + chunk
            };
          }
          return newMessages;
        });
      });
    } catch (error) {
      console.error('Chat Error:', error);
      setMessages(prev => {
        const newMessages = [...prev];
        const lastMsg = newMessages[newMessages.length - 1];
        if (lastMsg && lastMsg.role === 'ai') {
          // If empty, replace; if partial, append error
          if (!lastMsg.content) {
             newMessages[newMessages.length - 1] = { ...lastMsg, content: 'Sorry, I encountered an error processing the graph data for chat.' };
          } else {
             newMessages[newMessages.length - 1] = { ...lastMsg, content: lastMsg.content + '\n\n[Connection Error]' };
          }
        }
        return newMessages;
      });
    } finally {
      setIsLoading(false);
    }
  };

  return (
    <div className="flex flex-col h-full bg-nodal-card border-l border-gray-700">
      {/* Header */}
      <div className="p-4 border-b border-gray-700 bg-nodal-dark/50 shadow-sm flex-shrink-0">
        <h3 className="text-lg font-semibold text-white flex items-center gap-2">
          <Bot className="text-blue-500" />
          Graph Assistant
        </h3>
        <p className="text-xs text-gray-400 mt-1">Analyzing character connections & timeline</p>
      </div>

      {/* Messages */}
      <div className="flex-1 overflow-y-auto p-4 space-y-6 custom-scrollbar relative">
        {messages.map((msg, idx) => (
          <div key={idx} className={`flex ${msg.role === 'user' ? 'justify-end' : 'justify-start'}`}>
            <div 
              className={`max-w-[90%] rounded-2xl px-4 py-3 shadow-md ${
                msg.role === 'user' 
                  ? 'bg-blue-600 text-white rounded-br-none' 
                  : 'bg-gray-800 text-gray-100 rounded-bl-none border border-gray-700'
              }`}
            >
              {msg.role === 'user' ? (
                <p className="text-sm">{msg.content}</p>
              ) : (
                <>
                  {msg.content ? (
                    <FormattedMessage text={msg.content} />
                  ) : (
                    /* Initial Loading State for empty AI message */
                    <div className="flex gap-1 py-1">
                      <div className="w-1.5 h-1.5 bg-blue-500 rounded-full animate-bounce [animation-delay:-0.3s]"></div>
                      <div className="w-1.5 h-1.5 bg-blue-500 rounded-full animate-bounce [animation-delay:-0.15s]"></div>
                      <div className="w-1.5 h-1.5 bg-blue-500 rounded-full animate-bounce"></div>
                    </div>
                  )}
                </>
              )}
            </div>
          </div>
        ))}

        {/* Removed redundant standalone isLoading spinner, as the empty message bubble now shows loading dots */}
        
        {/* Large Preset Questions (Only show when chat is brand new/empty) */}
        {messages.length === 1 && !isLoading && (
           <div className="animate-in fade-in slide-in-from-bottom-4 duration-500 delay-100 px-2 mt-4">
              <p className="text-[10px] text-gray-500 uppercase tracking-widest font-bold mb-3 pl-1">Suggested Questions</p>
              <div className="grid grid-cols-1 gap-2">
                {PRESET_QUESTIONS.map((q, i) => (
                  <button
                    key={i}
                    onClick={() => handleSend(q)}
                    className="flex items-center gap-3 w-full text-left px-4 py-3 rounded-xl bg-gray-800/40 border border-gray-700/50 hover:bg-gray-700/80 hover:border-blue-500/30 hover:text-blue-100 transition-all group"
                  >
                    <div className="p-1.5 rounded-full bg-blue-500/10 text-blue-500 group-hover:bg-blue-500/20 group-hover:scale-110 transition-all">
                      <Sparkles size={14} />
                    </div>
                    <span className="text-sm text-gray-300 group-hover:text-white font-medium">{q}</span>
                  </button>
                ))}
              </div>
           </div>
        )}
        
        <div ref={messagesEndRef} />
      </div>

      {/* Input Area Wrapper */}
      <div className="bg-nodal-dark/30 border-t border-gray-700 flex-shrink-0 z-20">
        
        {/* Small Preset Chips (Visible when chat has history, "pills" style above input) */}
        {messages.length > 1 && !isLoading && (
          <div className="px-4 pt-3 pb-1 overflow-x-auto flex gap-2 no-scrollbar mask-fade-right">
            {PRESET_QUESTIONS.map((q, i) => (
              <button
                key={i}
                onClick={() => handleSend(q)}
                className="flex items-center gap-1.5 whitespace-nowrap px-3 py-1.5 rounded-full bg-gray-800/80 border border-gray-700 text-xs text-gray-300 hover:bg-blue-600 hover:text-white hover:border-blue-500 transition-all active:scale-95 flex-shrink-0"
              >
                <MessageSquare size={12} className="opacity-70" />
                {q}
              </button>
            ))}
          </div>
        )}

        {/* Input Field */}
        <div className="p-4 pt-2">
          <div className="flex gap-2 relative">
            <input
              type="text"
              value={input}
              onChange={(e) => setInput(e.target.value)}
              onKeyDown={(e) => e.key === 'Enter' && handleSend()}
              placeholder="Ask about phases, summaries, or relationships..."
              className="flex-1 bg-gray-900 border border-gray-600 rounded-xl px-4 py-3 text-sm text-white focus:outline-none focus:border-blue-500 focus:ring-1 focus:ring-blue-500 placeholder-gray-500 transition-all pr-12"
              disabled={isLoading || !analysisResult}
            />
            <button
              onClick={(e) => handleSend(e)}
              disabled={isLoading || !input.trim() || !analysisResult}
              className="absolute right-1.5 top-1.5 bg-blue-600 hover:bg-blue-700 disabled:opacity-30 disabled:cursor-not-allowed text-white p-2 rounded-lg transition-all active:scale-95"
            >
              <Send size={18} />
            </button>
          </div>
          <p className="text-[10px] text-center text-gray-500 mt-2">Gemini 3 Flash Analysis</p>
        </div>
      </div>
    </div>
  );
};

export default ChatPanel;
